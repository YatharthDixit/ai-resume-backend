const logger = require('../utils/logger');
const Run = require('../models/run.model');
const Process = require('../models/process.model');
const Resume = require('../models/resume.model');
const Pdf = require('../models/pdf.model');
const parserService = require('./parser.service');
const processService = require('./process.service');
const generationService = require('./generation.service');
const { PROCESS_STATUS } = require('../utils/constants');

class WorkerService {
  /**
   * Main message handler.
   */
  async handleMessage(message) {
    const { runId } = JSON.parse(message.Body);
    logger.info(`[${runId}] Received job from SQS`);

    // Ensure Process record exists
    let job = await Process.findOne({ runId });
    if (!job) {
      job = await Process.create({ runId, status: PROCESS_STATUS.PENDING });
    }

    try {
      // TWO-PASS ARCHITECTURE (Atomic State Transitions)

      // 1. TRY CLAIM: PENDING -> PARSING
      // We attempt to atomically update. If it returns null, either it's not pending (done/processing) or doesn't exist.
      let claimedJob = await Process.findOneAndUpdate(
        { runId, status: PROCESS_STATUS.PENDING },
        { status: PROCESS_STATUS.PARSING },
        { new: true }
      );

      // If we successfully claimed it (or it was already claimed by US if we are retrying logic? SQS retry is stateless)
      // Actually, if we are in PARSING state, we might be retrying.
      // So we check: Did we claim it OR is it already PARSING (retry case)?
      // For strict duplicate prevention, we only process if WE transitioned it.
      // BUT, if the previous worker crashed, status stays PARSING. We need to handle that.
      // Strategy: If PENDING -> We claim. If PARSING -> We continue (assuming retry).
      
      // Let's refine:
      // Case A: Fresh Job. Status PENDING.
      // Case B: Retry Job (previous crash). Status PARSING.
      // Case C: Duplicate Job (currently running). Status PARSING.
      
      // To solve Case C, we rely on SQS Visibility Timeout. If SQS gave us the message, we assume we own it.
      // But if user sent DUPLICATE SQS messages, SQS thinks they are different.
      
      // Strict Atomic Approach:
      if (claimedJob) {
        // We won the race for PENDING.
        await this.processParseStep(runId, claimedJob);
      } else {
        // We didn't transition from PENDING. Check if it's already ready for Step 2 or needs retry.
        job = await Process.findOne({ runId });
        
        // If it's still PARSING, it implies either:
        // 1. Another worker is busy (Duplicate Message) -> We should SKIP.
        // 2. Previous worked crashed (Retry) -> We should RETRY.
        // We can differentiate by checking `updatedAt`. If it's old (> 5 mins), retry. Else skip.
        
        // For now, let's trust the atomic transition for the "Fast Race".
        if (job.status === PROCESS_STATUS.PARSING) {
             const fiveMinutesAgo = new Date(Date.now() - 5 * 60 * 1000);
             if (job.updatedAt < fiveMinutesAgo) {
                 logger.warn(`[${runId}] Stale PARSING state detected. Retrying...`);
                 await this.processParseStep(runId, job);
             } else {
                 logger.info(`[${runId}] Job is already being parsed by another worker. Skipping.`);
             }
        }
      }

      // 2. TRY CLAIM: PARSED -> GENERATING
      claimedJob = await Process.findOneAndUpdate(
          { runId, status: PROCESS_STATUS.PARSED },
          { status: PROCESS_STATUS.GENERATING },
          { new: true }
      );

      if (claimedJob) {
          await this.processGenerateStep(runId, claimedJob);
      } else {
          // Check for stale GENERATING
          job = await Process.findOne({ runId });
          if (job.status === PROCESS_STATUS.GENERATING) {
              const fiveMinutesAgo = new Date(Date.now() - 5 * 60 * 1000);
               if (job.updatedAt < fiveMinutesAgo) {
                   logger.warn(`[${runId}] Stale GENERATING state detected. Retrying...`);
                   await this.processGenerateStep(runId, job);
               } else {
                   logger.info(`[${runId}] Job is already being generated by another worker. Skipping.`);
               }
          } else if (job.status === PROCESS_STATUS.COMPLETED || job.status === PROCESS_STATUS.FAILED) {
              logger.info(`[${runId}] Job already reached terminal state: ${job.status}. skipping.`);
          }
      }

      // If we did work, logging happen inside methods.
      // If we skipped, we log "Skipping".
      // SQS Consumer will delete the message because we return successfully. This is correct for duplicates.

    } catch (err) {
      logger.error(err, `[${runId}] Job failed`);
      // Throwing error tells sqs-consumer NOT to delete the message (it will be visible again after timeout)
      throw err;
    }
  }

  /**
   * PASS 1: Parse Step
   * Downloads PDF, Extracts Text, Generates Original JSON, Calculates Baseline ATS Score.
   */
  async processParseStep(runId, job) {
    logger.info(`[${runId}] Starting Pass 1: Parse...`);
    // Note: status is already set to PARSING by the atomic claim
    // But we might update timestamps if needed.

    try {
      const run = await Run.findOne({ runId });
      if (!run) throw new Error('Associated Run document not found.');

      // A. Download & Extract
      const pdfDoc = await Pdf.findOne({ runId });
      if (!pdfDoc) throw new Error('PDF document not found.');
      const pdfBuffer = pdfDoc.data;

      const text = await parserService.extractText(pdfBuffer);

      // Save text to DB
      run.extractedText = text;
      await run.save();

      // 4. Generate Structured Data (Pass 1)
      const original_json = await generationService.generateStructuredData(run.extractedText, runId);

      // 5. Update Resume record
      await Resume.findOneAndUpdate(
        { runId },
        {
          runId,
          original_json,
        },
        { upsert: true, new: true }
      );

      // Transition to PARSED
      job.status = PROCESS_STATUS.PARSED;
      await job.save();
      logger.info(`[${runId}] Pass 1 Complete.`);
    } catch (error) {
      job.status = PROCESS_STATUS.FAILED;
      job.lastError = { message: error.message, stack: error.stack };
      await job.save();
      throw error;
    }
  }

  /**
   * PASS 2: Generate Step
   * Optimizes the content using User Instructions.
   */
  async processGenerateStep(runId, job) {
    logger.info(`[${runId}] Starting Pass 2: Generate...`);
    // Note: status is already set to GENERATING by the atomic claim

    try {
      const run = await Run.findOne({ runId }).select('+extractedText');
      const resume = await Resume.findOne({ runId });

      // Read text from DB
      const text = run.extractedText;
      if (!text) throw new Error('Extracted text not found in Run document.');

      // 3. Optimize (Pass 2)
      // Note: We use the extracted text as context + the specific instruction
      const final_json = await generationService.optimizeStructuredData(
        run.extractedText,
        run.instruction_text,
        runId,
        run.job_description // Pass JD if it exists
      );

      // 4. Save Final JSON
      await Resume.findOneAndUpdate({ runId }, { final_json });

      // 5. Generate ATS Report (If JD exists)
      if (run.job_description) {
        // Need to fetch original_json for comparison
        // (resume variable already has it, but let's be safe and use what we have)
        const original_json = resume.original_json;

        const atsReport = await generationService.generateAtsReport(
          original_json,
          final_json,
          run.job_description,
          runId
        );

        if (atsReport) {
          await Resume.findOneAndUpdate({ runId }, {
            'atsScore.pre': atsReport.originalScore || 0,
            'atsScore.post': atsReport.generatedScore || 0,
            'atsScore.missingKeywords': atsReport.missingKeywords || [],
            'atsScore.summary': atsReport.changesSummary || ''
          });
        }
      }

      // D. Complete Job
      await processService.completeGenerateJob(job._id);
      logger.info(`[${runId}] Pass 2 Complete. Job Finished.`);
    } catch (error) {
      await processService.failJob(job._id, error);
      throw error;
    }
  }
}

module.exports = new WorkerService();
